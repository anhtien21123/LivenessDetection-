{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Thêm các thư viện"
      ],
      "metadata": {
        "id": "iRK4W_aD3qUz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pI0214Bq3jif"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLANwcaG3upS",
        "outputId": "5e2e9d2d-8bd1-4780-f348-10e1017846de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import multiprocessing\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, zip_path, mode='train', transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            zip_path (str): Đường dẫn tới file zip chứa các hình ảnh.\n",
        "            mode (str): 'train' hoặc 'test', để chỉ định thư mục nào sẽ được sử dụng.\n",
        "            transform (callable, optional): Các phép biến đổi được áp dụng lên ảnh.\n",
        "        \"\"\"\n",
        "        self.zip_path = zip_path\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "\n",
        "        # Mở file zip\n",
        "        self.zip_file = zipfile.ZipFile(zip_path, 'r')\n",
        "\n",
        "        # Tạo danh sách các file ảnh và nhãn từ thư mục tương ứng\n",
        "        self.image_labels = []\n",
        "        for file_name in self.zip_file.namelist():\n",
        "            if file_name.startswith(f\"{mode}_img/{mode}_img/color\") and file_name.endswith(\".jpg\"):\n",
        "                # Trích xuất nhãn từ tên file (giả sử nhãn nằm sau dấu gạch dưới cuối cùng)\n",
        "                label = 1 if file_name.split('_')[-1].split('.')[0] == \"real\" else 0\n",
        "                self.image_labels.append((file_name, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Trả về số lượng mẫu trong dataset.\"\"\"\n",
        "        return len(self.image_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Tải và trả về một mẫu từ dataset.\n",
        "        Args:\n",
        "            idx (int): Chỉ số của mẫu cần tải.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, label) tương ứng với ảnh và nhãn của nó.\n",
        "        \"\"\"\n",
        "        img_name, label = self.image_labels[idx]\n",
        "\n",
        "        # Đọc dữ liệu hình ảnh từ file zip\n",
        "        with self.zip_file.open(img_name) as img_file:\n",
        "            image = Image.open(io.BytesIO(img_file.read())).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Chuyển đổi label thành tensor\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "DG_750LL3wdh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "DXR2G8Es4GhB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/MyData/Casia-fasd.zip'\n",
        "train_dataset = CustomDataset(zip_path=zip_path, mode='train', transform=transform)\n",
        "test_dataset = CustomDataset(zip_path=zip_path, mode='test', transform=transform)\n",
        "print(len(train_dataset), len(test_dataset))\n",
        "\n",
        "# Tính toán số lượng luồng dựa trên số lượng CPU cores\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmNSx7VV4HMY",
        "outputId": "2050348a-28fe-41b4-ab6d-2964f1f89979"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1655 2408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "\n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "\n",
        "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "\n",
        "        #downsample if needed\n",
        "        if self.i_downsample is not None:\n",
        "            identity = self.i_downsample(identity)\n",
        "        #add identity\n",
        "        x+=identity\n",
        "        x=self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      identity = x.clone()\n",
        "\n",
        "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
        "      x = self.batch_norm2(self.conv2(x))\n",
        "\n",
        "      if self.i_downsample is not None:\n",
        "          identity = self.i_downsample(identity)\n",
        "      print(x.shape)\n",
        "      print(identity.shape)\n",
        "      x += identity\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
        "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
        "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
        "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
        "        ii_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
        "            ii_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
        "            )\n",
        "\n",
        "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
        "        self.in_channels = planes*ResBlock.expansion\n",
        "\n",
        "        for i in range(blocks-1):\n",
        "            layers.append(ResBlock(self.in_channels, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "def ResNet50(num_classes, channels=3):\n",
        "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)"
      ],
      "metadata": {
        "id": "AO39T7Gi474j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "patience = 10  # Số epoch chờ đợi trước khi dừng sớm nếu không có cải thiện\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "UsgwLPMT5u9f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping variables\n",
        "best_loss = float('inf')\n",
        "early_stop_counter = 0\n",
        "best_model_path = \"best_model.pth\"\n",
        "train_losses = []\n",
        "val_losses = []"
      ],
      "metadata": {
        "id": "2_ppiIt553a2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(num_classes=2, channels=3)\n",
        "# model = MobileNetV3(model_mode=\"SMALL\", num_classes=2)\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "iLvW45t456oo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Training phase\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update running loss\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(epoch_loss)  # Lưu lại train loss\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in test_loader:\n",
        "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "            val_outputs = model(val_inputs)\n",
        "            val_loss = criterion(val_outputs, val_labels)\n",
        "            val_running_loss += val_loss.item() * val_inputs.size(0)\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(test_loader.dataset)\n",
        "    val_losses.append(val_epoch_loss)  # Lưu lại validation loss\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
        "\n",
        "    # Save the best model based on validation loss\n",
        "    torch.save(model.state_dict(), 'last_model.pth')\n",
        "    if val_epoch_loss < best_loss:\n",
        "        best_loss = val_epoch_loss\n",
        "        early_stop_counter = 0  # Reset early stopping counter\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f'Model saved with validation loss: {best_loss:.4f}')\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "\n",
        "    # Check for early stopping\n",
        "    # if early_stop_counter >= patience:\n",
        "        # print(f'Early stopping at epoch {epoch+1}')\n",
        "        # break\n",
        "\n",
        "print('Training finished.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "walt0ElG6PAh",
        "outputId": "f1e88d5a-f3b0-4c4a-a541-cfb2ec3a63b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Training Loss: 0.4145, Validation Loss: 0.8818\n",
            "Model saved with validation loss: 0.8818\n",
            "Epoch [2/50], Training Loss: 0.2508, Validation Loss: 0.5217\n",
            "Model saved with validation loss: 0.5217\n",
            "Epoch [3/50], Training Loss: 0.1778, Validation Loss: 0.4456\n",
            "Model saved with validation loss: 0.4456\n",
            "Epoch [4/50], Training Loss: 0.1920, Validation Loss: 0.3124\n",
            "Model saved with validation loss: 0.3124\n",
            "Epoch [5/50], Training Loss: 0.1153, Validation Loss: 0.4969\n",
            "Epoch [6/50], Training Loss: 0.1457, Validation Loss: 0.6294\n",
            "Epoch [7/50], Training Loss: 0.1338, Validation Loss: 0.8735\n",
            "Epoch [8/50], Training Loss: 0.1060, Validation Loss: 0.4661\n",
            "Epoch [9/50], Training Loss: 0.0871, Validation Loss: 0.5357\n",
            "Epoch [10/50], Training Loss: 0.0751, Validation Loss: 0.9665\n",
            "Epoch [11/50], Training Loss: 0.0779, Validation Loss: 0.4881\n",
            "Epoch [12/50], Training Loss: 0.0904, Validation Loss: 0.3349\n",
            "Epoch [13/50], Training Loss: 0.0719, Validation Loss: 0.5974\n",
            "Epoch [14/50], Training Loss: 0.0366, Validation Loss: 0.7330\n",
            "Epoch [15/50], Training Loss: 0.0402, Validation Loss: 0.5333\n",
            "Epoch [16/50], Training Loss: 0.0621, Validation Loss: 0.3625\n",
            "Epoch [17/50], Training Loss: 0.0839, Validation Loss: 0.3719\n",
            "Epoch [18/50], Training Loss: 0.0521, Validation Loss: 0.3938\n",
            "Epoch [19/50], Training Loss: 0.0772, Validation Loss: 0.4220\n",
            "Epoch [20/50], Training Loss: 0.0300, Validation Loss: 0.3891\n",
            "Epoch [21/50], Training Loss: 0.0302, Validation Loss: 6.4626\n",
            "Epoch [22/50], Training Loss: 0.0907, Validation Loss: 1.3522\n",
            "Epoch [23/50], Training Loss: 0.0307, Validation Loss: 0.3544\n",
            "Epoch [24/50], Training Loss: 0.0182, Validation Loss: 0.7241\n",
            "Epoch [25/50], Training Loss: 0.0221, Validation Loss: 0.5153\n",
            "Epoch [26/50], Training Loss: 0.0383, Validation Loss: 0.3688\n",
            "Epoch [27/50], Training Loss: 0.0207, Validation Loss: 0.4176\n",
            "Epoch [28/50], Training Loss: 0.0282, Validation Loss: 0.4611\n",
            "Epoch [29/50], Training Loss: 0.0191, Validation Loss: 0.3711\n",
            "Epoch [30/50], Training Loss: 0.0332, Validation Loss: 0.4071\n",
            "Epoch [31/50], Training Loss: 0.0117, Validation Loss: 0.4094\n",
            "Epoch [32/50], Training Loss: 0.0449, Validation Loss: 0.4077\n",
            "Epoch [33/50], Training Loss: 0.0439, Validation Loss: 0.6447\n",
            "Epoch [34/50], Training Loss: 0.0776, Validation Loss: 0.2734\n",
            "Model saved with validation loss: 0.2734\n",
            "Epoch [35/50], Training Loss: 0.0122, Validation Loss: 0.2552\n",
            "Model saved with validation loss: 0.2552\n",
            "Epoch [36/50], Training Loss: 0.0100, Validation Loss: 0.3978\n",
            "Epoch [37/50], Training Loss: 0.0239, Validation Loss: 0.4830\n",
            "Epoch [38/50], Training Loss: 0.0159, Validation Loss: 0.3990\n",
            "Epoch [39/50], Training Loss: 0.0092, Validation Loss: 0.4190\n",
            "Epoch [40/50], Training Loss: 0.2131, Validation Loss: 3.1837\n",
            "Epoch [41/50], Training Loss: 0.0956, Validation Loss: 0.4003\n",
            "Epoch [42/50], Training Loss: 0.0827, Validation Loss: 0.4043\n",
            "Epoch [43/50], Training Loss: 0.0225, Validation Loss: 0.6625\n",
            "Epoch [44/50], Training Loss: 0.0263, Validation Loss: 0.5578\n",
            "Epoch [45/50], Training Loss: 0.0169, Validation Loss: 0.5837\n",
            "Epoch [46/50], Training Loss: 0.0075, Validation Loss: 0.9352\n",
            "Epoch [47/50], Training Loss: 0.0050, Validation Loss: 0.6479\n",
            "Epoch [48/50], Training Loss: 0.0062, Validation Loss: 0.8348\n",
            "Epoch [49/50], Training Loss: 0.0090, Validation Loss: 0.7832\n",
            "Epoch [50/50], Training Loss: 0.0018, Validation Loss: 0.6452\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    total_time = 0.0\n",
        "    total_batches = len(test_loader)\n",
        "\n",
        "    with torch.no_grad():  # Không tính toán gradient trong quá trình đánh giá\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)  # Lấy nhãn dự đoán\n",
        "\n",
        "            end_time = time.time()\n",
        "            total_time += (end_time - start_time)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Chuyển danh sách dự đoán và nhãn thành numpy array\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Tính accuracy\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    # Tính các chỉ số FAR, FRR\n",
        "    tp = np.sum((all_labels == 1) & (all_preds == 1))  # True Positives\n",
        "    tn = np.sum((all_labels == 0) & (all_preds == 0))  # True Negatives\n",
        "    fp = np.sum((all_labels == 0) & (all_preds == 1))  # False Positives\n",
        "    fn = np.sum((all_labels == 1) & (all_preds == 0))  # False Negatives\n",
        "\n",
        "    # Tổng số lượng mẫu\n",
        "    num_fake = np.sum(all_labels == 0)  # Tổng số mẫu giả\n",
        "    num_real = np.sum(all_labels == 1)  # Tổng số mẫu thật\n",
        "\n",
        "    # Tính FAR, FRR\n",
        "    FAR = fp / num_fake if num_fake > 0 else 0\n",
        "    FRR = fn / num_real if num_real > 0 else 0\n",
        "\n",
        "    # Tính HTER\n",
        "    HTER = 0.5 * (FAR + FRR)\n",
        "\n",
        "    # Tính số lượng tham số của mô hình\n",
        "    num_parameters = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    # Tính thời gian thực hiện trung bình cho mỗi batch\n",
        "    avg_time_per_batch = total_time / total_batches\n",
        "\n",
        "    return accuracy, HTER, num_parameters, avg_time_per_batch"
      ],
      "metadata": {
        "id": "3ZBz0gLW6mru"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(num_classes=2, channels=3)\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))  # Tải mô hình đã huấn luyện\n",
        "model.to(device)\n",
        "\n",
        "accuracy, HTER, num_parameters, avg_time_per_batch = evaluate_model(model, test_loader, device)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'HTER: {HTER:.4f}')\n",
        "print(f'Prameters: {num_parameters}')\n",
        "print(f'Time: {avg_time_per_batch:.4f} s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_svyGUj8yhi",
        "outputId": "2cc2845c-bc18-4f02-883b-132bbfb2fb80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-ca4454c84dd3>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pth'))  # Tải mô hình đã huấn luyện\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9431\n",
            "HTER: 0.0588\n",
            "Prameters: 23538626\n",
            "Time: 0.0143 s\n"
          ]
        }
      ]
    }
  ]
}